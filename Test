import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.ticker import FuncFormatter

# ==========================================================
# PnL App — RESET (baseline minimal)
# Tabs: 1) PnL  2) Contributions  3) Régimes & Hedge (Top4)
# ==========================================================
st.set_page_config(page_title="PnL App — Baseline", layout="wide")
st.title("PnL • Contributions • Régimes (baseline)")

# ------------------------------
# Sidebar — Data & Parameters
# ------------------------------
st.sidebar.header("Fichiers CSV")
coeff_file   = st.sidebar.file_uploader("Coeff Matrix CSV (avec 'DataType' + facteurs)", type=["csv"])
mapping_file = st.sidebar.file_uploader("Mapping CSV (Index, Mapping, Bump)", type=["csv"])
market_file  = st.sidebar.file_uploader("Market Data CSV (Date + facteurs)", type=["csv"])

fx_cols_input = st.sidebar.text_input(
    "Colonnes FX en % (autres en Δ)",
    value="EURUSD,GBPUSD,USDJPY,USDCAD,EURGBP,EURJPY"
)
FX_COLS = [c.strip() for c in fx_cols_input.split(",") if c.strip()]

# ------------------------------
# Helpers
# ------------------------------
@st.cache_data(show_spinner=True)
def load_csvs(coeff_f, mapping_f, market_f):
    if coeff_f is None or mapping_f is None or market_f is None:
        raise ValueError("Merci d'uploader les 3 CSV (Coeff, Mapping, Market).")
    coeff = pd.read_csv(coeff_f)
    mapping = pd.read_csv(mapping_f)
    market = pd.read_csv(market_f, thousands=",")

    # Date parsing
    date_col = None
    for c in market.columns:
        if c.lower().strip() == "date":
            date_col = c; break
    if not date_col:
        raise ValueError("Le Market CSV doit contenir une colonne 'Date'.")
    market = market.rename(columns={date_col: "Date"})
    # try ISO then FR fallback
    try:
        market["Date"] = pd.to_datetime(market["Date"], errors="raise")
    except Exception:
        market["Date"] = pd.to_datetime(market["Date"], format="%d/%m/%Y", errors="coerce")
    if market["Date"].isna().any():
        raise ValueError("Impossible de parser certaines dates dans Market.")
    market = market.set_index("Date").sort_index()

    # Mapping normalization
    if "Index" not in mapping.columns:
        mapping = mapping.rename_axis("Index").reset_index()
    if "Bump" not in mapping.columns:
        mapping["Bump"] = 1.0
    if "Mapping" not in mapping.columns:
        mapping["Mapping"] = mapping["Index"]
    mapping = mapping[["Index","Mapping","Bump"]].copy()
    mapping["Index"] = mapping["Index"].astype(str)
    mapping = mapping.set_index("Index")

    if "DataType" not in coeff.columns:
        raise ValueError("Le fichier Coeff doit contenir une colonne 'DataType'.")

    return coeff, mapping, market


def build_changes(market_df: pd.DataFrame, fx_cols):
    pct_cols = [c for c in fx_cols if c in market_df.columns]
    diff_cols = [c for c in market_df.columns if c not in pct_cols]
    df_pct  = market_df[pct_cols].pct_change(1) * 100.0 if pct_cols else pd.DataFrame(index=market_df.index)
    df_diff = market_df[diff_cols].diff(1)              if diff_cols else pd.DataFrame(index=market_df.index)
    out = pd.concat([df_pct, df_diff], axis=1)
    return out.reindex(columns=list(market_df.columns))


def compute_pnl(coeff_df, mapping_df, market_df, dtype, fx_cols):
    risk_cols = list(market_df.columns)
    for c in risk_cols:
        if c not in coeff_df.columns:
            coeff_df[c] = 0.0
    mkt_change = build_changes(market_df, fx_cols).reindex(columns=risk_cols).dropna()
    if dtype not in risk_cols:
        raise ValueError(f"Le driver '{dtype}' doit exister dans Market Data.")
    row = coeff_df.loc[coeff_df["DataType"].astype(str) == str(dtype)]
    if row.empty:
        raise ValueError("DataType introuvable dans la matrice de coefficients.")
    v = row.iloc[0][risk_cols].astype(float)
    bumps = mapping_df.reindex(risk_cols)["Bump"].astype(float).where(lambda s: s > 0).fillna(1.0)

    risk_ts   = mkt_change.mul(v, axis=1).div(bumps, axis=1)
    step_risk = risk_ts.cumsum().diff().dropna()
    driver    = mkt_change[[dtype]].loc[step_risk.index]
    pnl_by_factor = step_risk.mul(driver[dtype], axis=0)
    net_daily = pnl_by_factor.sum(axis=1).rename("NetDailyPnL")
    return {"pnl_by_factor": pnl_by_factor, "net_daily": net_daily, "mkt_change": mkt_change}

# ------------------------------
# Load + Date range
# ------------------------------
try:
    coeff_df, mapping_df, market_df = load_csvs(coeff_file, mapping_file, market_file)
except Exception as e:
    st.info("Charge d'abord tes 3 CSV dans la sidebar.")
    st.stop()

min_date = market_df.index.min().date()
max_date = market_df.index.max().date()
start_date, end_date = st.sidebar.date_input(
    "Période",
    (min_date, max_date),
    min_value=min_date,
    max_value=max_date,
)
if isinstance(start_date, tuple):
    start_date, end_date = start_date  # compat old Streamlit
start_date = pd.to_datetime(start_date); end_date = pd.to_datetime(end_date)
if end_date < start_date:
    st.error("La date de fin est antérieure à la date de début.")
    st.stop()

market_df = market_df.loc[(market_df.index >= start_date) & (market_df.index <= end_date)]
if market_df.empty:
    st.warning("Aucune donnée de marché dans l'intervalle sélectionné.")
    st.stop()

# ------------------------------
# Compute PnL (select DataType)
# ------------------------------
dtypes_avail = sorted(coeff_df["DataType"].astype(str).unique())
dtype = st.sidebar.selectbox("Choisir DataType (driver)", options=dtypes_avail, index=0)
res = compute_pnl(coeff_df.copy(), mapping_df.copy(), market_df.copy(), dtype, FX_COLS)
pnl_by_factor = res["pnl_by_factor"]
net_daily = res["net_daily"]

# ------------------------------
# Tabs
# ------------------------------
tab1, tab2, tab3 = st.tabs([
    "Tab 1 — PnL",
    "Tab 2 — Contributions",
    "Tab 3 — Régimes & Hedge (Top4)",
])

# === Tab 1: PnL ===
with tab1:
    st.subheader(f"PnL — {dtype}")
    col1, col2 = st.columns(2)
    with col1:
        st.write("**PnL quotidien (récents en premier)**")
        df_daily = net_daily.reset_index().rename(columns={"index":"Date", net_daily.name:"PnL"})
        df_daily = df_daily.sort_values("Date", ascending=False)
        st.dataframe(
            df_daily.style.format({"PnL":"{:,.0f}"}).applymap(lambda v: "color:red;" if isinstance(v,(int,float)) and v<0 else "", subset=["PnL"]),
            use_container_width=True,
        )
    with col2:
        st.write("**PnL cumulatif (récents en premier)**")
        cum_pnl = net_daily.cumsum().rename("CumPnL")
        df_cum = cum_pnl.reset_index().rename(columns={"index":"Date"}).sort_values("Date", ascending=False)
        st.dataframe(
            df_cum.style.format({"CumPnL":"{:,.0f}"}).applymap(lambda v: "color:red;" if isinstance(v,(int,float)) and v<0 else "", subset=["CumPnL"]),
            use_container_width=True,
        )

    fig1, ax1 = plt.subplots(figsize=(12, 5), dpi=120)
    ax1.plot(net_daily.index, net_daily.values, label="PnL quotidien")
    ax1.set_xlabel("Date"); ax1.set_ylabel("PnL"); ax1.set_title(f"{dtype} — PnL quotidien")
    n1 = len(net_daily)
    if n1 < 120:
        locx1 = mdates.MonthLocator(interval=1); fmtx1 = mdates.DateFormatter("%b %Y")
    elif n1 < 300:
        locx1 = mdates.MonthLocator(interval=3); fmtx1 = mdates.DateFormatter("%b %Y")
    elif n1 < 700:
        locx1 = mdates.MonthLocator(interval=6); fmtx1 = mdates.DateFormatter("%b %Y")
    else:
        locx1 = mdates.YearLocator(); fmtx1 = mdates.DateFormatter("%Y")
    ax1.xaxis.set_major_locator(locx1); ax1.xaxis.set_major_formatter(fmtx1)
    ax1.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
    ax1.legend(loc="upper left"); st.pyplot(fig1)

    fig2, ax2 = plt.subplots(figsize=(12, 5), dpi=120)
    ax2.plot(cum_pnl.index, cum_pnl.values, label="PnL cumulatif")
    ax2.set_xlabel("Date"); ax2.set_ylabel("PnL cumulé"); ax2.set_title(f"{dtype} — PnL cumulatif")
    n2 = len(cum_pnl)
    if n2 < 120:
        locx2 = mdates.MonthLocator(interval=1); fmtx2 = mdates.DateFormatter("%b %Y")
    elif n2 < 300:
        locx2 = mdates.MonthLocator(interval=3); fmtx2 = mdates.DateFormatter("%b %Y")
    elif n2 < 700:
        locx2 = mdates.MonthLocator(interval=6); fmtx2 = mdates.DateFormatter("%b %Y")
    else:
        locx2 = mdates.YearLocator(); fmtx2 = mdates.DateFormatter("%Y")
    ax2.xaxis.set_major_locator(locx2); ax2.xaxis.set_major_formatter(fmtx2)
    ax2.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
    ax2.legend(loc="upper left"); st.pyplot(fig2)

    st.download_button(
        "Télécharger PnL (CSV)",
        data=pd.concat([net_daily.rename("PnL_daily"), cum_pnl], axis=1).to_csv().encode("utf-8"),
        file_name=f"{dtype}_PnL.csv",
        mime="text/csv",
    )

# === Tab 2: Contributions ===
with tab2:
    st.subheader("Contributions par constituant")
    total_pnl = pnl_by_factor.sum(axis=1).rename("TotalPnL")
    final_cum = pnl_by_factor.cumsum().iloc[-1].abs().sort_values(ascending=False)
    default_sel = list(final_cum.head(min(8,len(final_cum))).index)

    cols_sel = st.multiselect("Facteurs à afficher", list(pnl_by_factor.columns), default=default_sel)
    vmode = st.radio("Vue", ["Quotidiennes","Cumulatives"], index=0, horizontal=True)
    smode = st.radio("Style", ["Lignes","Aire empilée"], index=0, horizontal=True)

    if cols_sel:
        daily = pnl_by_factor[cols_sel]
        cumu  = daily.cumsum()
        figC, axC = plt.subplots(figsize=(12, 6), dpi=120)
        if vmode == "Quotidiennes":
            if smode == "Lignes":
                for c in cols_sel: axC.plot(daily.index, daily[c], label=c)
            else:
                axC.stackplot(daily.index, daily[cols_sel].T.values, labels=cols_sel)
            axC.set_ylabel("Contribution quotidienne")
        else:
            if smode == "Lignes":
                for c in cols_sel: axC.plot(cumu.index, cumu[c], label=c)
            else:
                axC.stackplot(cumu.index, cumu[cols_sel].T.values, labels=cols_sel)
            axC.set_ylabel("Contribution cumulative")
        axC.set_xlabel("Date"); axC.legend(loc="upper left", ncols=2)
        nC = len(daily)
        if nC < 120:
            locC = mdates.MonthLocator(interval=1); fmtC = mdates.DateFormatter("%b %Y")
        elif nC < 300:
            locC = mdates.MonthLocator(interval=3); fmtC = mdates.DateFormatter("%b %Y")
        elif nC < 700:
            locC = mdates.MonthLocator(interval=6); fmtC = mdates.DateFormatter("%b %Y")
        else:
            locC = mdates.YearLocator(); fmtC = mdates.DateFormatter("%Y")
        axC.xaxis.set_major_locator(locC); axC.xaxis.set_major_formatter(fmtC)
        axC.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
        st.pyplot(figC)
    else:
        st.info("Sélectionne au moins un facteur.")

    st.markdown("---")
    st.write("**Aperçu (30 derniers jours, récents en premier)**")
    prev = pnl_by_factor.tail(30).copy()
    prev = prev.reindex(index=prev.index.sort_values(ascending=False))
    prev.insert(0, "TotalPnL", total_pnl.reindex(prev.index))
    st.dataframe(prev.style.format("{:,.0f}").applymap(lambda v: "color:red;" if isinstance(v,(int,float)) and v<0 else ""), use_container_width=True)

    c1, c2 = st.columns(2)
    with c1:
        st.download_button("Télécharger contributions (quotidien)", data=pnl_by_factor.to_csv().encode("utf-8"), file_name=f"{dtype}_pnl_contributions_daily.csv")
    with c2:
        st.download_button("Télécharger contributions (cumulé)", data=pnl_by_factor.cumsum().to_csv().encode("utf-8"), file_name=f"{dtype}_pnl_contributions_cum.csv")

# === Tab 3: Régimes & Hedge (Top4 self-hedge) ===
with tab3:
    st.subheader("Régimes (K-Means) + Hedge self (Top 4)")

    # K-Means sur contributions quotidiennes
    X = pnl_by_factor.replace([np.inf,-np.inf], np.nan).dropna(how="any")
    if X.empty:
        st.info("Contributions insuffisantes pour K-Means.")
        st.stop()

    from sklearn.cluster import KMeans

    c0, c1, c2 = st.columns(3)
    with c0:
        K = st.slider("Nombre de régimes (K)", 2, 8, 3, 1)
    with c1:
        seed = st.number_input("Seed", 0, 10000, 42, 1)
    with c2:
        min_seg = st.number_input("Min. longueur segment (jours)", 1, 20, 2, 1)

    Xz = (X - X.mean())/X.std().replace(0,np.nan)
    Xz = Xz.fillna(0.0)
    km = KMeans(n_clusters=int(K), n_init=10, random_state=int(seed))
    labels_raw = pd.Series(km.fit_predict(Xz), index=Xz.index, name="cluster")

    # Lissage visuel
    def _segments(idx, labs):
        out=[]; s=0; cur=labs[0]
        for i in range(1,len(labs)):
            if labs[i]!=cur: out.append((s,i-1,cur)); s=i; cur=labs[i]
        out.append((s,len(labs)-1,cur)); return out
    Lvals = labels_raw.values.copy()
    for s,e,L in _segments(labels_raw.index.to_list(), Lvals):
        if int(min_seg)>1 and (e-s+1)<int(min_seg):
            if s>0: Lvals[s:e+1]=Lvals[s-1]
            elif e+1<len(Lvals): Lvals[s:e+1]=Lvals[e+1]
    labels = pd.Series(Lvals, index=labels_raw.index, name="cluster")

    # Triggers
    lv = labels.reindex(pnl_by_factor.index).fillna(-1).astype(int).values
    dates = pnl_by_factor.index.to_list()
    triggers = []
    for i in range(1,len(lv)):
        if lv[i]!=lv[i-1]: triggers.append((dates[i], int(lv[i])))

    # Graphique PnL total + aplats régimes
    net_daily = pnl_by_factor.sum(axis=1)
    figk, axk = plt.subplots(figsize=(12,5), dpi=120)
    axk.plot(net_daily.index, net_daily.values, label="PnL quotidien (total)", lw=1.1)
    import matplotlib.cm as cm
    cmap = cm.get_cmap("tab10", int(K))
    for s,e,L in _segments(net_daily.index.to_list(), lv):
        if L==-1: continue
        x0,x1 = net_daily.index[s], net_daily.index[e]
        axk.axvspan(x0,x1,color=cmap(L),alpha=0.08)
    if triggers:
        axk.vlines([d for d,_ in triggers], ymin=float(net_daily.min()), ymax=float(net_daily.max()), linestyles=":", color="red", alpha=0.25)
    axk.set_title("PnL total — Régimes (K-Means)"); axk.set_xlabel("Date"); axk.set_ylabel("PnL")
    npts = len(net_daily)
    if npts<120: loc = mdates.MonthLocator(1); fmt = mdates.DateFormatter("%b %Y")
    elif npts<300: loc = mdates.MonthLocator(3); fmt = mdates.DateFormatter("%b %Y")
    elif npts<700: loc = mdates.MonthLocator(6); fmt = mdates.DateFormatter("%b %Y")
    else: loc = mdates.YearLocator(); fmt = mdates.DateFormatter("%Y")
    axk.xaxis.set_major_locator(loc); axk.xaxis.set_major_formatter(fmt)
    axk.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
    axk.legend(loc="upper left"); st.pyplot(figk)

    st.markdown("---")
    st.subheader("Top 4 du jour de trigger — Hedge self (DV01/FX01)")

    # Driver (Δ) à partir du Market
    mkt_change = build_changes(market_df, FX_COLS)
    if dtype not in mkt_change.columns:
        st.warning(f"Driver '{dtype}' introuvable dans Market.")
        st.stop()
    driver = mkt_change[dtype].astype(float)

    if len(triggers)==0:
        st.info("Aucun trigger détecté.")
    else:
        # Upload PV (DV01/FX01)
        # ⚙️ Option DV01/FX01 sans CSV (éditeur in‑app)
        use_pv = st.toggle("Activer le calcul DV01/FX01 (sans CSV)", value=False,
                           help="Calcule un notionnel de hedge si tu renseignes des UnitPerNotional.")

        # Heuristique simple pour typer un constituant
        def _type_of(name: str) -> str:
            u = str(name).upper()
            if name in FX_COLS: return "FX"
            if ("XCCY" in u) or ("BASIS" in u): return "XCCY"
            return "RATES"

        if use_pv:
            pv_mode = st.radio("Source des UnitPerNotional", ["Par familles (défauts)", "Saisie manuelle (éditeur)"], horizontal=True)
            if pv_mode == "Par familles (défauts)":
                cfa, cfb, cfc = st.columns(3)
                with cfa:
                    default_rates = st.number_input("Default Rates (DV01 par 1 notional)", 0.0, 1e9, 100.0, 1.0)
                with cfb:
                    default_xccy  = st.number_input("Default XCCY (DV01 par 1 notional)", 0.0, 1e9, 100.0, 1.0)
                with cfc:
                    default_fx    = st.number_input("Default FX (FX01 par 1 notional)", 0.0, 1e9, 1000.0, 1.0)
            else:
                st.caption("Saisis/édite les UnitPerNotional dans la table juste en dessous (colonne éditable).")

        d_opts = [pd.to_datetime(d) for d,_ in triggers]
        d_sel = st.selectbox("Date trigger", options=sorted(d_opts), index=len(d_opts)-1, format_func=lambda x: x.strftime("%Y-%m-%d"))

        if d_sel not in pnl_by_factor.index:
            st.warning("Date hors plage des contributions.")
        else:
            row = pnl_by_factor.loc[d_sel]
            top4 = row.abs().sort_values(ascending=False).head(4).index.tolist()
            d_move = float(driver.reindex(pnl_by_factor.index).get(d_sel, np.nan))
            out = []
            for c in top4:
                pnl_c = float(row[c])
                risk_delta = (pnl_c/d_move) if (np.isfinite(d_move) and abs(d_move)>1e-12) else np.nan
                upn = float(pv_map.get(str(c), np.nan)) if pv_map else np.nan
                hedge_units = -risk_delta if np.isfinite(risk_delta) else np.nan
                hedge_notional = (hedge_units/upn) if (np.isfinite(hedge_units) and np.isfinite(upn) and upn!=0) else np.nan
                out.append({
                    "Date": d_sel,
                    "Cluster": int(labels.loc[d_sel]) if d_sel in labels.index else np.nan,
                    "Constituant": c,
                    "PnL_contrib": pnl_c,
                    f"Driver(Δ{dtype})": d_move,
                    "RiskDelta (units)": risk_delta,
                })": d_move,
                    "RiskDelta (units)": risk_delta,
                    "UnitPerNotional (DV01/FX01)": upn,
                    "HedgeUnits_self": hedge_units,
                    "HedgeNotional_self": hedge_notional,
                })
            view = pd.DataFrame(out)

            # Nouvelle colonne : DV01/FX01 total à hedger (absolu)
            view["DV01/FX01 à hedger"] = (
                view["HedgeNotional_self (implied)"].abs() * view["Implied UnitPerNotional"].abs()
            )

            # Paramètre α (pour ne pas tout hedger)
            alpha_pct = st.slider("α — % du risque à hedger", 0, 100, 100, 5,
                                  help="Appliqué à la DV01/FX01 à hedger et aux tailles de hedge affichées.") / 100.0
            # Synchronise α avec la simulation PnL
            st.session_state["alpha_top4"] = float(alpha_pct)
            view["DV01/FX01 à hedger (α)"] = view["DV01/FX01 à hedger"] * alpha_pct
            # On affiche aussi les tailles de hedge pondérées par α pour référence
            view["HedgeUnits_self (α)"] = view["HedgeUnits_self"] * alpha_pct
            view["HedgeNotional_self (implied, α)"] = view["HedgeNotional_self (implied)"] * alpha_pct
            # Δ en unités du constituant à trader pour neutraliser sa contribution PnL
            view["HedgeUnits_self"] = -view["RiskDelta (units)"]

            if use_pv:
                # Pré‑remplissage UnitPerNotional par familles ou éditeur manuel
                view["Type"] = view["Constituant"].map(_type_of)
                if pv_mode == "Par familles (défauts)":
                    def _pv_prefill(t):
                        if t == "FX": return default_fx
                        if t == "XCCY": return default_xccy
                        return default_rates
                    view["UnitPerNotional"] = view["Type"].map(_pv_prefill)
                else:
                    if "UnitPerNotional" not in view.columns:
                        view["UnitPerNotional"] = np.nan
                    view = st.data_editor(
                        view,
                        use_container_width=True,
                        num_rows="fixed",
                        column_config={
                            "UnitPerNotional": st.column_config.NumberColumn("UnitPerNotional (DV01/FX01)", step=0.0001),
                        },
                        disabled=["Date","Cluster","Constituant","PnL_contrib",f"Driver(Δ{dtype})","RiskDelta (units)","Type"],
                    )
                # Calcul notionnels si PV renseigné
                view["HedgeUnits_self"] = -view["RiskDelta (units)"]
                view["HedgeNotional_self"] = np.where(
                    view["UnitPerNotional"].replace(0, np.nan).notna(),
                    view["HedgeUnits_self"] / view["UnitPerNotional"],
                    np.nan,
                )
                fmt_dict = {
                    "PnL_contrib": "{:,.0f}",
                    f"Driver(Δ{dtype})": "{:,.6f}",
                    "RiskDelta (units)": "{:,.6f}",
                    "UnitPerNotional": "{:,.6f}",
                    "HedgeUnits_self": "{:,.6f}",
                    "HedgeNotional_self": "{:,.4f}",
                }
                st.dataframe(
                    view.style.format(fmt_dict).applymap(
                        lambda v: "color:red;" if isinstance(v, (int, float)) and v < 0 else "",
                        subset=["PnL_contrib","RiskDelta (units)","HedgeUnits_self","HedgeNotional_self"]
                    ),
                    use_container_width=True,
                )
            else:
                st.dataframe(
                view[["Date","Cluster","Constituant","Type","PnL_contrib",f"Driver(Δ{dtype})","RiskDelta (units)","Implied UnitPerNotional","HedgeUnits_self","HedgeUnits_self (α)","HedgeNotional_self (implied)","HedgeNotional_self (implied, α)","DV01/FX01 à hedger","DV01/FX01 à hedger (α)"]]
                .style.format({
                    "PnL_contrib": "{:,.0f}",
                    f"Driver(Δ{dtype})": "{:,.6f}",
                    "RiskDelta (units)": "{:,.6f}",
                    "Implied UnitPerNotional": "{:,.6f}",
                    "HedgeUnits_self": "{:,.6f}",
                    "HedgeNotional_self (implied)": "{:,.4f}",
                    "HedgeUnits_self (α)": "{:,.6f}",
                    "HedgeNotional_self (implied, α)": "{:,.4f}",
                    "DV01/FX01 à hedger": "{:,.0f}",
                    "DV01/FX01 à hedger (α)": "{:,.0f}",
                }).applymap(lambda v: "color:red;" if isinstance(v,(int,float)) and v<0 else "",
                            subset=["PnL_contrib","RiskDelta (units)","HedgeUnits_self","HedgeNotional_self (implied)"]),
                use_container_width=True,
            )

            st.download_button(
                "Télécharger (CSV) — Top4 & Hedge self",
                data=view.to_csv(index=False).encode("utf-8"),
                file_name=f"top4_trigger_{d_sel.date()}_{dtype}.csv",
                mime="text/csv",
            )


# =========================
# (Global) Simulation — PnL non-hedgé vs hedgé (Top 4 @ triggers)
# =========================
# S'appuie sur les variables calculées dans Tab 3: pnl_by_factor, triggers, driver, FX_COLS
try:
    assert isinstance(pnl_by_factor, pd.DataFrame) and not pnl_by_factor.empty
    assert 'triggers' in locals() or 'triggers' in globals()
    _trigs = triggers if 'triggers' in locals() else globals().get('triggers', [])
    assert len(_trigs) >= 0
except Exception:
    pass
else:
    st.markdown("---")
    st.subheader("Simulation — PnL non-hedgé vs hedgé (Top 4 @ triggers)")

    sim1, sim2, sim4 = st.columns(3)
    with sim1:
        hedge_alpha = st.slider("Fraction de hedge α", 0.0, 1.0, 1.0, 0.05,
                                help="1.0 = neutralisation complète de la contribution du constituant")
    # Si α défini dans l'onglet Top4, on l'utilise pour la simulation
    _alpha_top4 = st.session_state.get("alpha_top4", None)
    if _alpha_top4 is not None:
        hedge_alpha = float(_alpha_top4)
    with sim2:
        reduce_days = st.number_input("Durée d'effet (jours)", 1, 10, 1, 1)
    with sim4:
        st.caption("Coûts de hedge (bp de notionnel)")
        cost_rate_bp = st.number_input("Rates", 0.00, 10.00, 0.20, 0.01, key="g_cost_rates")
        cost_xccy_bp = st.number_input("XCCY", 0.00, 10.00, 0.25, 0.01, key="g_cost_xccy")
        cost_fx_bp   = st.number_input("FX",    0.00, 10.00, 0.00, 0.01, key="g_cost_fx")

    # UPV implicite pour le coût
    lookback_days_sim = st.number_input("Lookback (jours) pour UPV implicite — coût", 5, 2520, 90, 5)
    def implied_unit_per_notional_sim(constituant: str, lookback: int | None) -> float:
        s = pnl_by_factor[constituant].astype(float)
        drv = driver if 'driver' in locals() or 'driver' in globals() else build_changes(market_df, FX_COLS)[dtype].astype(float)
        x = drv.reindex(s.index).astype(float)
        r = s / x.replace(0, np.nan)
        r = r.replace([np.inf, -np.inf], np.nan).dropna()
        if lookback is not None and int(lookback) > 0:
            r = r.tail(int(lookback))
        if r.empty:
            return np.nan
        return float(np.nanmedian(r.values))

    contrib_after = pnl_by_factor.copy()
    cost_series = pd.Series(0.0, index=contrib_after.index)

    def _type_of(name: str) -> str:
        u = str(name).upper()
        if name in FX_COLS: return "FX"
        if ("XCCY" in u) or ("BASIS" in u): return "XCCY"
        return "RATES"

    all_dates = sorted(list({pd.to_datetime(d) for d,_ in _trigs})) if len(_trigs)>0 else []

    # Reconstitue plans Top4 sur toutes les dates
    def _top4_for_date(dd):
        if dd not in pnl_by_factor.index:
            return []
        rowd = pnl_by_factor.loc[dd]
        top4d = rowd.abs().sort_values(ascending=False).head(4).index.tolist()
        # driver devrait être défini dans Tab 3
        dmove = float(driver.reindex(pnl_by_factor.index).get(dd, np.nan)) if 'driver' in locals() or 'driver' in globals() else np.nan
        outs = []
        for c in top4d:
            pnl_c = float(rowd[c])
            risk_delta = (pnl_c / dmove) if (np.isfinite(dmove) and abs(dmove) > 1e-12) else np.nan
            hedge_units = -risk_delta if np.isfinite(risk_delta) else 0.0
            outs.append({
                "Date": dd,
                "Constituant": c,
                "Type": _type_of(c),
                "PnL_contrib": pnl_c,
                "RiskDelta": risk_delta,
                "HedgeUnits": hedge_units,
            })
        return outs

    plans = []
    for dd,_L in _trigs:
        plans.extend(_top4_for_date(pd.to_datetime(dd)))
    plans_df = pd.DataFrame(plans)

    # Appliquer réduction des contributions
    if not plans_df.empty:
        for dd, subp in plans_df.groupby("Date"):
            for k in range(0, int(reduce_days)):
                dt = pd.to_datetime(dd) + pd.Timedelta(days=k)
                if dt not in contrib_after.index:
                    continue
                for _, r in subp.iterrows():
                    c = r["Constituant"]
                    contrib_after.loc[dt, c] = contrib_after.loc[dt, c] * (1.0 - float(hedge_alpha))

            # Coût implicite via UPV implicite (100% implicite)
            for _, r in subp.iterrows():
                c = r["Constituant"]; typ = r["Type"]
                upv = implied_unit_per_notional_sim(c, lookback_days_sim)
                if not np.isfinite(upv) or upv == 0:
                    continue
                notional = abs(float(r["HedgeUnits"]) * float(hedge_alpha)) / upv
                bp = cost_fx_bp if typ=="FX" else (cost_xccy_bp if typ=="XCCY" else cost_rate_bp)
                amt = notional * (float(bp) * 1e-4)
                debit_day = pd.to_datetime(dd)
                if debit_day in cost_series.index:
                    cost_series.loc[debit_day] += float(amt)

    pnl_base  = pnl_by_factor.sum(axis=1).rename("PnL_baseline")
    pnl_after = contrib_after.sum(axis=1).rename("PnL_hedged") - cost_series
    cum_base  = pnl_base.cumsum()
    cum_after = pnl_after.cumsum()

    fig_cmp, ax_cmp = plt.subplots(figsize=(12,5), dpi=120)
    ax_cmp.plot(cum_base.index,  cum_base.values,  label="Non-hedgé (Baseline)")
    ax_cmp.plot(cum_after.index, cum_after.values, label="Hedgé")
    if len(all_dates)>0:
        ax_cmp.vlines(all_dates,
                      ymin=min(float(cum_after.min()), float(cum_base.min())),
                      ymax=max(float(cum_after.max()), float(cum_base.max())),
                      linestyles=":", alpha=0.2, color="red", label="Triggers")
    ax_cmp.set_title("Cumulative PnL — Baseline vs Hedgé (Top 4 @ triggers)")
    ax_cmp.set_xlabel("Date"); ax_cmp.set_ylabel("Cumulative PnL")
    npts = len(cum_after)
    if npts < 120:
        locx = mdates.MonthLocator(interval=1); fmtx = mdates.DateFormatter("%b %Y")
    elif npts < 300:
        locx = mdates.MonthLocator(interval=3); fmtx = mdates.DateFormatter("%b %Y")
    elif npts < 700:
        locx = mdates.MonthLocator(interval=6); fmtx = mdates.DateFormatter("%b %Y")
    else:
        locx = mdates.YearLocator(); fmtx = mdates.DateFormatter("%Y")
    ax_cmp.xaxis.set_major_locator(locx)
    ax_cmp.xaxis.set_major_formatter(fmtx)
    ax_cmp.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
    ax_cmp.legend(loc="upper left")
    st.pyplot(fig_cmp)

    fig_d, ax_d = plt.subplots(figsize=(12,5), dpi=120)
    ax_d.plot(pnl_base.index,  pnl_base.values,  label="PnL quotidien — baseline", lw=1.1)
    ax_d.plot(pnl_after.index, pnl_after.values, label="PnL quotidien — hedgé",   lw=1.1)
    if len(all_dates)>0:
        ax_d.vlines(all_dates,
                    ymin=min(float(pnl_after.min()), float(pnl_base.min())),
                    ymax=max(float(pnl_after.max()), float(pnl_base.max())),
                    linestyles=":", alpha=0.2, color="red", label="Triggers")
    ax_d.set_title("PnL quotidien — baseline vs hedgé (Top 4 @ triggers)")
    ax_d.set_xlabel("Date"); ax_d.set_ylabel("PnL/jour")
    ax_d.xaxis.set_major_locator(locx)
    ax_d.xaxis.set_major_formatter(fmtx)
    ax_d.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f"{v:,.0f}"))
    ax_d.legend(loc="upper left")
    st.pyplot(fig_d)

    total_cost = float(cost_series.sum())
    improvement = float(cum_after.iloc[-1] - cum_base.iloc[-1])
    k1, k2 = st.columns(2)
    with k1: st.metric("Coût total de hedge", f"{total_cost:,.0f}")
    with k2: st.metric("Δ PnL cumulé (Hedgé - Baseline)", f"{improvement:,.0f}")

    out_series = pd.concat([
        pnl_base,
        pnl_after,
        cum_base.rename("CumPnL_baseline"),
        cum_after.rename("CumPnL_hedged"),
        cost_series.rename("HedgeCost")
    ], axis=1)
    st.download_button(
        "Télécharger séries (CSV) — Baseline vs Hedgé",
        data=out_series.to_csv().encode("utf-8"),
        file_name=f"{dtype}_baseline_vs_hedged_top4_global.csv",
        mime="text/csv",
    )
