# =========================
# TAB 3 — Clustering KNN (Spectral) + Table des entrées & DV01/FX01 (Coeff_total incluant DataType)
# =========================
try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    from matplotlib.ticker import FuncFormatter

    st.header("Régimes (Clustering K-Means — Euclidien) + DV01/FX01 par constituant (Coeff_total incluant DataType)")

    # ---- Hyperparams & inputs ----
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        n_clusters = st.slider("Nombre de clusters (K)", 2, 10, 3, 1, key="km_clust_K")
    with c2:
        n_init = st.number_input("n_init (restarts)", 1, 50, 10, 1, key="km_clust_ninit")
    with c3:
        top_n = st.slider("Top N constituants par date", 1, 20, 4, 1, key="km_clust_topn")
    with c4:
        alpha_cov = st.slider("α — % à couvrir", 0, 100, 100, 5, key="km_clust_alpha")/100.0

    # ---- Coeff_total (somme de tous les scénarios + DataType inclus) ----
    coeff_cols = [c for c in coeff_df.columns if str(c) != "DataType"]
    coeff_total = (
        coeff_df.set_index("DataType")[coeff_cols]
        .astype(float)
        .sum(axis=1)
        .add(coeff_df.set_index("DataType").index.to_series().apply(lambda x: 0.0 if pd.isna(x) else 0.0))  # inclut DataType pour cohérence structurelle
        .reindex(risk_cols)
    )
    bump_s = (
        mapping_df.reindex(risk_cols)["Bump"]
        .astype(float)
        .where(lambda s: s.notna() & (s != 0.0))
    )
    dv01_per_unit = (coeff_total / bump_s).replace([np.inf, -np.inf], np.nan)

    # ---- Clustering K-Means (Euclidien) sur contributions ----
    X = pnl_by_factor.fillna(0.0)
    scaler = StandardScaler()
    Xz = scaler.fit_transform(X)

    kmeans = KMeans(n_clusters=int(n_clusters), n_init=int(n_init), random_state=42)
    labels_arr = kmeans.fit_predict(Xz)
    labels_knn = pd.Series(labels_arr, index=X.index, name="cluster")

    # ---- Statistiques descriptives par cluster (neutre) ----
    net_on_lbl = pd.concat([net_daily, labels_knn], axis=1).dropna()
    cluster_stats = (
        net_on_lbl.groupby('cluster')['NetDailyPnL']
        .agg(['size','mean','std'])
        .rename(columns={'size':'n_days','mean':'mean_pnl','std':'std_pnl'})
        .sort_index()
    )

    # ---- Transitions de régime (toutes transitions, pas seulement "mauvais") ----
    entries = []
    prev = None
    for dt, lab in labels_knn.items():
        if prev is None:
            prev = lab
            continue
        if lab != prev:
            entries.append(dt)
        prev = lab

    # ---- Graphique des régimes (coloration par cluster) ----
    figR, axR = plt.subplots(figsize=(12,5), dpi=120)
    axR.plot(net_daily.index, net_daily.values, lw=1.1, label='PnL quotidien')
    cmap = plt.cm.get_cmap('tab10', int(n_clusters))
    for c in range(int(n_clusters)):
        mask = labels_knn == c
        axR.fill_between(net_daily.index, net_daily.values, 0,
                         where=mask.reindex(net_daily.index).fillna(False),
                         color=cmap(c), alpha=0.18, label=f'Cluster {c}')
    if len(entries):
        axR.vlines(entries, ymin=min(float(net_daily.min()),0.0), ymax=max(float(net_daily.max()),0.0),
                    linestyles=':', color='black', alpha=0.4, label='Changement de régime')
    axR.yaxis.set_major_formatter(FuncFormatter(lambda v,_: f"{v:,.0f}"))
    axR.set_title('K-Means — Régimes de marché (neutre, tous clusters)')
    axR.legend(loc='upper left', ncols=2)
    st.pyplot(figR)

    st.subheader("Statistiques par cluster")
    try:
        st.dataframe(
            cluster_stats.style.format({
                'n_days': '{:.0f}',
                'mean_pnl': '{:,.0f}',
                'std_pnl': '{:,.0f}'
            }),
            use_container_width=True
        )
    except Exception:
        st.dataframe(cluster_stats, use_container_width=True)

    # ---- Table Top-N ----
    rows = []
    for d in entries:
        if d not in pnl_by_factor.index:
            continue
        pnl_row = pnl_by_factor.loc[d].reindex(risk_cols)
        dS_row  = mkt_change.loc[d].reindex(risk_cols) if d in mkt_change.index else pd.Series(index=risk_cols, dtype=float)
        topN = pnl_row.abs().sort_values(ascending=False).head(int(top_n)).index.tolist()
        for c in topN:
            pnl_c = float(pnl_row.get(c, np.nan))
            dS_i  = float(dS_row.get(c, np.nan))
            bump_c = float(bump_s.get(c, np.nan))
            coeff_tot_c = float(coeff_total.get(c, np.nan))
            dv01_unit_c = float(dv01_per_unit.get(c, np.nan))
            if np.isfinite(dS_i) and abs(dS_i) > 1e-12:
                hedge_100 = -(pnl_c / dS_i)
                logic = "−PnL/ΔS"
            elif np.isfinite(bump_c) and abs(bump_c) > 1e-12:
                hedge_100 = -(pnl_c / bump_c)
                logic = "−PnL/Bump (fallback)"
            else:
                hedge_100 = np.nan
                logic = "n/a"
            hedge_alpha = hedge_100 * float(alpha_cov) if np.isfinite(hedge_100) else np.nan
            rows.append({
                "Date": d,
                "Constituant": c,
                "PnL_contrib": pnl_c,
                "MarketMove ΔS_i": dS_i,
                "Bump (Mapping)": bump_c,
                "Coeff_total (∑ scénarios + DataType)": coeff_tot_c,
                "DV01/FX01 per-unit (Coeff_total/Bump)": dv01_unit_c,
                "Hedge100% (−PnL/ΔS)": hedge_100,
                "Hedge(α×)": hedge_alpha,
                "Logic": logic,
            })

    tbl_entries = pd.DataFrame(rows)
    if not tbl_entries.empty:
        tbl_entries["AbsPnL"] = tbl_entries["PnL_contrib"].abs()
        tbl_entries = tbl_entries.sort_values(["Date","AbsPnL"], ascending=[True, False]).drop(columns=["AbsPnL"])

    # ---- Display ----
    st.subheader("Top N constituants par date — PnL, moves & DV01/FX01 (Coeff_total incluant DataType)")
    if tbl_entries.empty:
        st.info("Table vide.")
    else:
        st.dataframe(
            tbl_entries.style.format({
                "PnL_contrib":"{:,.0f}",
                "MarketMove ΔS_i":"{:,.6f}",
                "Bump (Mapping)":"{:,.6f}",
                "Coeff_total (∑ scénarios + DataType)":"{:,.0f}",
                "DV01/FX01 per-unit (Coeff_total/Bump)":"{:,.0f}",
                "Hedge100% (−PnL/ΔS)":"{:,.0f}",
                "Hedge(α×)":"{:,.0f}",
            }).applymap(lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else '', subset=['PnL_contrib','Hedge100% (−PnL/ΔS)','Hedge(α×)']),
            use_container_width=True
        )
        st.download_button(
            "Télécharger (CSV) — Entrées & DV01/FX01 total (Clustering KNN)",
            data=tbl_entries.to_csv(index=False).encode('utf-8'),
            file_name=f"knnclust_entries_dv01_total_{dtype}.csv",
            mime="text/csv",
        )
except Exception as _e_knn_simple:
    st.warning(f"Tab 3 (Clustering KNN total) non rendue: {_e_knn_simple}")

# =========================
# Tab 3 — Coût de hedge & PnL Hedged vs Baseline (total scénarios)
# =========================
try:
    st.subheader("Coût de hedge et PnL net (Total scénarios)")
    if 'tbl_entries' in globals() and isinstance(tbl_entries, pd.DataFrame) and not tbl_entries.empty:
        c1, c2, c3 = st.columns(3)
        with c1:
            cost_rate = st.number_input("Coût — Rates (par DV01)", 0.0, 5.0, 0.20, 0.01, key="cost_rate_knn_total")
        with c2:
            cost_xccy  = st.number_input("Coût — XCCY (par DV01)", 0.0, 5.0, 0.25, 0.01, key="cost_xccy_knn_total")
        with c3:
            cost_fx    = st.number_input("Coût — FX (par FX01)",   0.0, 5.0, 0.00, 0.01, key="cost_fx_knn_total")

        def _bucket_total(name: str) -> str:
            n = str(name).upper()
            if 'FX' in n or (('FX_COLS' in globals()) and (name in FX_COLS)):
                return 'FX'
            if 'XCCY' in n or 'BASIS' in n:
                return 'XCCY'
            return 'Rates'

        # Série de coûts sur les dates d'entrée: somme(|Hedge(α×)| * coût par bucket)
        cost_series = pd.Series(0.0, index=net_daily.index)
        for d, sub in tbl_entries.groupby('Date'):
            tot = 0.0
            for _, r in sub.iterrows():
                units_alpha = r.get('Hedge(α×)', np.nan)
                if not np.isfinite(units_alpha) or units_alpha == 0:
                    continue
                bucket = _bucket_total(r.get('Constituant',''))
                if bucket == 'FX':
                    tot += abs(units_alpha) * float(cost_fx)
                elif bucket == 'XCCY':
                    tot += abs(units_alpha) * float(cost_xccy)
                else:
                    tot += abs(units_alpha) * float(cost_rate)
            if d in cost_series.index:
                cost_series.loc[d] += tot

        # Appliquer α au jour d'entrée (pas d'effet durée)
        contrib_after = pnl_by_factor.copy()
        for d, sub in tbl_entries.groupby('Date'):
            if d not in contrib_after.index:
                continue
            cols = sub['Constituant'].unique().tolist()
            contrib_after.loc[d, cols] = contrib_after.loc[d, cols] * (1.0 - float(alpha_cov))

        pnl_base  = pnl_by_factor.sum(axis=1).rename('PnL_baseline')
        pnl_hedge = (contrib_after.sum(axis=1) - cost_series).rename('PnL_hedged_net')
        cum_base, cum_hedge = pnl_base.cumsum(), pnl_hedge.cumsum()

        fig_net, ax_net = plt.subplots(figsize=(12,5), dpi=120)
        ax_net.plot(cum_base.index, cum_base.values, label='Baseline')
        ax_net.plot(cum_hedge.index, cum_hedge.values, label='Hedged (net coût)')
        if 'entries' in globals() and len(entries)>0:
            ax_net.vlines(entries,
                          ymin=min(float(cum_base.min()), float(cum_hedge.min())),
                          ymax=max(float(cum_base.max()), float(cum_hedge.max())),
                          linestyles=':', color='red', alpha=0.35, label='Entrées négatives')
        ax_net.yaxis.set_major_formatter(FuncFormatter(lambda v,_: f"{v:,.0f}"))
        # Axe X adaptatif
        npts=len(cum_base)
        if npts<120:
            locx=mdates.MonthLocator(interval=1); fmtx=mdates.DateFormatter('%b %Y')
        elif npts<300:
            locx=mdates.MonthLocator(interval=3); fmtx=mdates.DateFormatter('%b %Y')
        elif npts<700:
            locx=mdates.MonthLocator(interval=6); fmtx=mdates.DateFormatter('%b %Y')
        else:
            locx=mdates.YearLocator(); fmtx=mdates.DateFormatter('%Y')
        ax_net.xaxis.set_major_locator(locx); ax_net.xaxis.set_major_formatter(fmtx)
        ax_net.set_title('Cumulative PnL — Baseline vs Hedged (net coût) — Total scénarios')
        ax_net.legend(loc='upper left')
        st.pyplot(fig_net)

        # KPIs
        tot_cost = float(cost_series.sum())
        pnl_diff = float(cum_hedge.iloc[-1] - cum_base.iloc[-1])
        k1, k2 = st.columns(2)
        with k1: st.metric("Coût total hedge", f"{tot_cost:,.0f}")
        with k2: st.metric("Δ PnL cumulé (Hedged - Baseline)", f"{pnl_diff:,.0f}")
    else:
        st.info("Table d'entrées vide — aucun coût/graphique à afficher.")
except Exception as _e_knn_cost_total:
    st.warning(f"Coût & PnL net (total scénarios) non rendus: {_e_knn_cost_total}")
# =========================
# TAB 4 — Détection de transition (supervisé) : proba de changement de régime
# =========================
try:
    st.header("Détection de transition — Probabilité de changement de régime (ML)")

    # --- Hyperparams & choix modèle ---
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        horizon_next = st.slider("Horizon détection (jours)", 1, 10, 3, 1, key="trans_horizon")
    with c2:
        n_lags = st.slider("Nb de lags ΔS", 1, 10, 3, 1, key="trans_nlags")
    with c3:
        test_size_pct = st.slider("Test size % (chronologique)", 10, 50, 20, 5, key="trans_testpct") / 100.0
    with c4:
        alert_thr = st.slider("Seuil alerte proba", 10, 90, 70, 5, key="trans_thr") / 100.0

    # --- Assurer des labels de régime depuis Tab 3 (sinon recalcul rapide) ---
    if 'labels_knn' not in globals() or not isinstance(labels_knn, pd.Series) or labels_knn.empty:
        from sklearn.cluster import KMeans
        from sklearn.preprocessing import StandardScaler
        X_tmp = pnl_by_factor.fillna(0.0)
        scaler_tmp = StandardScaler()
        Xz_tmp = scaler_tmp.fit_transform(X_tmp)
        n_clusters_tmp = 3
        kmeans_tmp = KMeans(n_clusters=n_clusters_tmp, n_init=10, random_state=42)
        labels_knn = pd.Series(kmeans_tmp.fit_predict(Xz_tmp), index=X_tmp.index, name="cluster")

    # --- Déterminer les transitions (toutes transitions entre clusters) ---
    trans_dates = []
    prev_lab = None
    for dt, lab in labels_knn.items():
        if prev_lab is None:
            prev_lab = lab
            continue
        if lab != prev_lab:
            trans_dates.append(dt)
        prev_lab = lab

    # --- Construire labels supervisés : 1 si transition dans les 'horizon_next' jours ---
    all_idx = mkt_change.index.intersection(labels_knn.index)
    y = pd.Series(0, index=all_idx, dtype=int)
    trans_set = set(pd.to_datetime(trans_dates))
    for t in all_idx:
        # si une transition survient dans [t+1, t+horizon_next]
        future_window = [t + pd.Timedelta(days=h) for h in range(1, int(horizon_next)+1)]
        if any(f in trans_set for f in future_window):
            y.loc[t] = 1

    # --- Features : lags de ΔS (mkt_change)
    X_feat_list = []
    for lag in range(0, int(n_lags)):
        if lag == 0:
            X_feat_list.append(mkt_change.reindex(all_idx).add_suffix(f"_lag0"))
        else:
            X_feat_list.append(mkt_change.shift(lag).reindex(all_idx).add_suffix(f"_lag{lag}"))
    X_feat = pd.concat(X_feat_list, axis=1).dropna()

    # Aligner X et y, enlever NaNs éventuels
    y = y.reindex(X_feat.index).fillna(0).astype(int)

    # --- Split chronologique ---
    n_total = len(X_feat)
    n_test = max(1, int(np.floor(test_size_pct * n_total)))
    n_train = n_total - n_test
    X_train, X_test = X_feat.iloc[:n_train], X_feat.iloc[n_train:]
    y_train, y_test = y.iloc[:n_train], y.iloc[n_train:]

    # --- Modèle : LightGBM si dispo, sinon RandomForest ---
    model_name = None
    proba_train = proba_test = None
    try:
        import lightgbm as lgb
        model = lgb.LGBMClassifier(n_estimators=400, learning_rate=0.05, num_leaves=31,
                                   subsample=0.9, colsample_bytree=0.9, random_state=42)
        model.fit(X_train, y_train)
        proba_train = model.predict_proba(X_train)[:,1]
        proba_test  = model.predict_proba(X_test)[:,1]
        model_name = "LightGBM"
    except Exception:
        from sklearn.ensemble import RandomForestClassifier
        model = RandomForestClassifier(n_estimators=400, max_depth=None, min_samples_leaf=2, random_state=42)
        model.fit(X_train, y_train)
        proba_train = model.predict_proba(X_train)[:,1]
        proba_test  = model.predict_proba(X_test)[:,1]
        model_name = "RandomForest"

    # --- AUC (si possible) ---
    auc_train = auc_test = np.nan
    try:
        from sklearn.metrics import roc_auc_score
        auc_train = roc_auc_score(y_train, proba_train) if (y_train.nunique()>1) else np.nan
        auc_test  = roc_auc_score(y_test,  proba_test)  if (y_test.nunique()>1)  else np.nan
    except Exception:
        pass

    # --- Série de probas sur tout l'échantillon ---
    # On réentraîne sur tout et prédit proba sur toute la période pour affichage
    try:
        model.fit(X_feat, y)
        proba_all = pd.Series(model.predict_proba(X_feat)[:,1], index=X_feat.index, name="proba_transition")
    except Exception:
        proba_all = pd.Series(index=X_feat.index, dtype=float, name="proba_transition")

    # --- Affichage KPIs ---
    k1, k2, k3 = st.columns(3)
    with k1: st.metric("Modèle", model_name or "?")
    with k2: st.metric("AUC (train)", f"{auc_train:.3f}" if np.isfinite(auc_train) else "n/a")
    with k3: st.metric("AUC (test)",  f"{auc_test:.3f}"  if np.isfinite(auc_test)  else "n/a")

    # --- Graphique des probabilités ---
    figP, axP = plt.subplots(figsize=(12,4), dpi=120)
    axP.plot(proba_all.index, proba_all.values, lw=1.1, label='Proba transition (t→t+H)')
    axP.axhline(alert_thr, linestyle='--')
    # Marquer transitions réelles
    if len(trans_dates):
        axP.vlines(trans_dates, ymin=0, ymax=1, linestyles=':', color='black', alpha=0.3, label='Transitions réelles')
    axP.set_ylim(0,1)
    axP.set_title(f"Probabilité de changement de régime — modèle {model_name}")
    st.pyplot(figP)

    # --- Proba actuelle + Alerte hedge ---
    if len(proba_all)>0:
        prob_today = float(proba_all.iloc[-1])
        st.metric("Proba (aujourd'hui)", f"{prob_today*100:.1f}%")
        if prob_today >= alert_thr:
            st.warning("Alerte : probabilité de changement de régime élevée — envisager un hedge partiel.")
        else:
            st.info("Probabilité sous le seuil d'alerte.")

    # --- Export CSV ---
    out_pred = pd.concat([
        y.rename("label_transition_nextH"),
        proba_all
    ], axis=1)
    st.download_button(
        "Télécharger (CSV) — Probabilités de transition",
        data=out_pred.to_csv().encode('utf-8'),
        file_name="transition_probabilities.csv",
        mime="text/csv"
    )
except Exception as _e_tab4:
    st.warning(f"Tab 4 (Détection de transition) non rendue: {_e_tab4}")

