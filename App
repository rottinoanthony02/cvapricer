# pnl_app_6tabs_hmm_lgbm.py
# ------------------------------------------------------------
# Streamlit — 6 tabs:
# 1) PnL global (quotidien + cumul)
# 2) Contributions par constituant (sélection libre)
# 3) Hedge piloté par LightGBM (α = f(proba_all)) + coûts + agrégat par colonne
# 4) LightGBM supervision (détection transition) + proba_all + comparatif HMM vs LGBM
# 5) HMM par constituant (probabilité de stress pondérée)
# 6) Forecast & Hedge Optimizer (LightGBM -> α -> plan de hedge T/T+1)
#
# Notes:
# - Compat scikit-learn: KMeans/KNN retirés (remplacés par HMM/LGBM)
# - Robustesse CSV: détection auto Date, thousands="," sur Market
# - FX gérés en pct_change*100; autres en diff
# - Export CSV pour PnL, contributions, sizing, baseline vs hedged, etc.
# ------------------------------------------------------------

import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.ticker import FuncFormatter
from matplotlib.patches import Patch

st.set_page_config(page_title="PnL + Contributions + Régimes + Hedge", layout="wide")
st.title("PnL + Contributions + Régimes (HMM/LGBM) + Hedge")

# =========================
# Sidebar — Inputs & Uploads
# =========================
st.sidebar.header("Données (CSV)")
# IMPORTANT: on place la période en 1er comme demandé
period_placeholder = st.sidebar.empty()  # rempli après parsing des CSV

coeff_file   = st.sidebar.file_uploader("Coeff Matrix CSV (DataType + facteurs/scénarios)", type=["csv"])
mapping_file = st.sidebar.file_uploader("Mapping CSV (Index, Mapping, Bump)", type=["csv"])
market_file  = st.sidebar.file_uploader("Market Data CSV (Date + facteurs)", type=["csv"])

fx_cols_input = st.sidebar.text_input(
    "Colonnes FX traitées en % (autres en différences)",
    value="EURUSD,GBPUSD,USDJPY,USDCAD,EURGBP,EURJPY"
)
FX_COLS = [c.strip() for c in fx_cols_input.split(",") if c.strip()]

# =========================
# Helpers
# =========================
@st.cache_data(show_spinner=True)
def load_csvs(coeff_f, mapping_f, market_f):
    if coeff_f is None or mapping_f is None or market_f is None:
        raise ValueError("Merci d'uploader les 3 CSV (Coeff, Mapping, Market).")

    coeff = pd.read_csv(coeff_f)
    mapping = pd.read_csv(mapping_f)
    market = pd.read_csv(market_f, thousands=",")

    # Market: parse Date robuste
    dcol = None
    for c in market.columns:
        if c.lower().strip() == "date":
            dcol = c; break
    if dcol is None:
        raise ValueError("Le Market CSV doit contenir une colonne 'Date'.")
    market = market.rename(columns={dcol: "Date"})

    parsed = None
    # Essais de parsing multi-formats
    for fmt in [None, "%d/%m/%Y", "%Y-%m-%d", "%m/%d/%Y"]:
        try:
            parsed = pd.to_datetime(market["Date"], format=fmt, errors="raise")
            break
        except Exception:
            continue
    if parsed is None:
        # dernier essai en coerce pour détecter
        parsed = pd.to_datetime(market["Date"], errors="coerce")
    if parsed.isna().any():
        bad = market.loc[parsed.isna(), "Date"].head(5).astype(str).tolist()
        raise ValueError(f"Impossible de parser certaines dates (exemples: {bad}). Vérifie le format.")
    market["Date"] = parsed
    market = market.set_index("Date").sort_index()

    # Mapping
    if "Index" not in mapping.columns:
        mapping = mapping.rename_axis("Index").reset_index()
    if "Bump" not in mapping.columns:
        mapping["Bump"] = 1.0
    if "Mapping" not in mapping.columns:
        mapping["Mapping"] = mapping["Index"]
    mapping = mapping[["Index", "Mapping", "Bump"]].copy()
    mapping["Index"] = mapping["Index"].astype(str)
    mapping = mapping.set_index("Index")

    if "DataType" not in coeff.columns:
        raise ValueError("Le fichier Coeff doit contenir une colonne 'DataType'.")

    return coeff, mapping, market

def build_changes(market_df, fx_cols):
    pct_cols = [c for c in fx_cols if c in market_df.columns]
    diff_cols = [c for c in market_df.columns if c not in pct_cols]
    df_pct  = market_df[pct_cols].pct_change(1) * 100.0 if pct_cols else pd.DataFrame(index=market_df.index)
    df_diff = market_df[diff_cols].diff(1)             if diff_cols else pd.DataFrame(index=market_df.index)
    out = pd.concat([df_pct, df_diff], axis=1)
    out = out.reindex(columns=list(market_df.columns))
    return out.dropna()

def compute_pnl(coeff_df, mapping_df, market_df, dtype, fx_cols):
    risk_cols = [c for c in market_df.columns]  # index date, colonnes risques

    # complétion des colonnes manquantes dans coeff_df
    for c in risk_cols:
        if c not in coeff_df.columns:
            coeff_df[c] = 0.0

    # ΔS
    mkt_change = build_changes(market_df, fx_cols).reindex(columns=risk_cols).dropna()

    if dtype not in risk_cols:
        raise ValueError(f"Le driver '{dtype}' doit exister dans Market Data.")

    # Vector pour dtype
    row = coeff_df.loc[coeff_df["DataType"].astype(str) == str(dtype)]
    if row.empty:
        raise ValueError("DataType introuvable dans la matrice de coefficients.")
    v = row.iloc[0][risk_cols].astype(float)

    bumps = mapping_df.reindex(risk_cols)["Bump"].astype(float).where(lambda s: s.notna() & (s != 0.0)).fillna(1.0)

    # Risk time series + PnL
    risk_ts   = mkt_change.mul(v, axis=1).div(bumps, axis=1)
    cum_risk  = risk_ts.cumsum()
    step_risk = cum_risk.diff().dropna()
    driver    = mkt_change[[dtype]].loc[step_risk.index]
    pnl_by_factor = step_risk.mul(driver[dtype], axis=0)   # contributions quotidiennes par facteur
    net_daily = pnl_by_factor.sum(axis=1).rename("NetDailyPnL")
    cum_pnl   = net_daily.cumsum().rename("CumPnL")

    return {
        "risk_cols": risk_cols,
        "mkt_change": mkt_change,
        "vector": v,
        "bumps": bumps,
        "pnl_by_factor": pnl_by_factor,
        "net_daily": net_daily,
        "cum_pnl": cum_pnl,
    }

def zscore_df(df: pd.DataFrame) -> pd.DataFrame:
    mu = df.mean()
    sd = df.std().replace(0, np.nan)
    return (df - mu) / sd

def format_yaxis_plain(ax):
    try:
        ax.yaxis.set_major_formatter(FuncFormatter(lambda v,_: f"{v:,.0f}"))
    except Exception:
        pass

def auto_xticks(ax, idx):
    # Ajuste densité de ticks selon longueur
    n = len(idx)
    if n <= 60:
        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%d-%b"))
    elif n <= 400:
        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%b %Y"))
    else:
        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%b %Y"))

# =========================
# Load data
# =========================
try:
    coeff_df, mapping_df, market_df = load_csvs(coeff_file, mapping_file, market_file)
except Exception as e:
    st.error(str(e))
    st.stop()

# Période (sidebar en tout premier affichage)
min_date = market_df.index.min().date()
max_date = market_df.index.max().date()
with period_placeholder.container():
    period = st.sidebar.date_input(
        "Période des prix",
        (min_date, max_date),
        min_value=min_date,
        max_value=max_date,
    )

# gérer retour (date unique ou tuple)
if isinstance(period, tuple) and len(period) == 2:
    start_date, end_date = period
else:
    start_date, end_date = min_date, max_date
start_date = pd.to_datetime(start_date)
end_date   = pd.to_datetime(end_date)
if end_date < start_date:
    st.error("La date de fin est antérieure à la date de début.")
    st.stop()

# Filtrage de la période
market_df = market_df.loc[(market_df.index >= start_date) & (market_df.index <= end_date)]
if market_df.empty:
    st.warning("Aucune donnée de marché dans l'intervalle sélectionné.")
    st.stop()

# Choix DataType
dtype = st.selectbox("Choisir DataType (driver)", sorted([c for c in market_df.columns]))

# Calcul PnL
try:
    res = compute_pnl(coeff_df, mapping_df, market_df, dtype, FX_COLS)
except Exception as e:
    st.error(str(e))
    st.stop()

risk_cols     = res["risk_cols"]
mkt_change    = res["mkt_change"]
v             = res["vector"]
bumps         = res["bumps"]
pnl_by_factor = res["pnl_by_factor"]
net_daily     = res["net_daily"]
cum_pnl       = res["cum_pnl"]

# =========================
# Tabs
# =========================
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "Tab 1 — PnL",
    "Tab 2 — Contributions",
    "Tab 3 — Hedge (LightGBM α)",
    "Tab 4 — LightGBM Transition",
    "Tab 5 — HMM par constituant",
    "Tab 6 — Forecast & Hedge Optimizer",
])

# ---------------------------------------------------------
# TAB 1 — PnL global
# ---------------------------------------------------------
with tab1:
    st.subheader(f"PnL — {dtype}")

    col1, col2 = st.columns(2)
    with col1:
        st.write("**PnL quotidien (récent → ancien)**")
        tbl = net_daily.reset_index().rename(columns={"index": "Date"})
        tbl = tbl.sort_values("Date", ascending=False)
        try:
            st.dataframe(tbl.style.format({"NetDailyPnL": "{:,.0f}"}).applymap(
                lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else '', subset=['NetDailyPnL']
            ), use_container_width=True, height=360)
        except Exception:
            st.dataframe(tbl, use_container_width=True, height=360)
    with col2:
        st.write("**PnL cumulatif (récent → ancien)**")
        tblc = cum_pnl.reset_index().rename(columns={"index": "Date"}).sort_values("Date", ascending=False)
        try:
            st.dataframe(tblc.style.format({"CumPnL": "{:,.0f}"}).applymap(
                lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else '', subset=['CumPnL']
            ), use_container_width=True, height=360)
        except Exception:
            st.dataframe(tblc, use_container_width=True, height=360)

    fig1, ax1 = plt.subplots(figsize=(12, 5), dpi=120)
    ax1.plot(net_daily.index, net_daily.values, label="PnL quotidien")
    ax1.set_xlabel("Date"); ax1.set_ylabel("PnL")
    ax1.set_title(f"{dtype} — PnL quotidien")
    format_yaxis_plain(ax1); auto_xticks(ax1, net_daily.index)
    ax1.legend(loc="upper left")
    st.pyplot(fig1)

    fig2, ax2 = plt.subplots(figsize=(12, 5), dpi=120)
    ax2.plot(cum_pnl.index, cum_pnl.values, label="PnL cumulatif")
    ax2.set_xlabel("Date"); ax2.set_ylabel("PnL cumulé")
    ax2.set_title(f"{dtype} — PnL cumulatif")
    format_yaxis_plain(ax2); auto_xticks(ax2, cum_pnl.index)
    ax2.legend(loc="upper left")
    st.pyplot(fig2)

    export_df = pd.concat([net_daily, cum_pnl], axis=1)
    st.download_button(
        "Télécharger PnL (CSV)",
        data=export_df.to_csv().encode("utf-8"),
        file_name=f"{dtype}_PnL.csv",
        mime="text/csv",
    )

# ---------------------------------------------------------
# TAB 2 — Contributions
# ---------------------------------------------------------
with tab2:
    st.subheader("Contributions par constituant")

    # Top defaults par contribution cumulée absolue
    final_cum_contrib = pnl_by_factor.cumsum().iloc[-1].abs().sort_values(ascending=False)
    default_choices = list(final_cum_contrib.head(min(8, len(final_cum_contrib))).index)

    cols_choose = st.multiselect(
        "Choisis les facteurs à afficher",
        risk_cols,
        default=default_choices,
    )

    view_mode = st.radio("Vue", ["Cumulatives", "Quotidiennes"], horizontal=True, index=0)
    style_mode = st.radio("Style", ["Lignes", "Aire empilée"], horizontal=True, index=0)

    if cols_choose:
        to_plot_daily = pnl_by_factor[cols_choose].copy()
        to_plot_cum   = to_plot_daily.cumsum()

        fig3, ax3 = plt.subplots(figsize=(12, 6), dpi=120)
        if view_mode == "Quotidiennes":
            if style_mode == "Lignes":
                for c in cols_choose:
                    ax3.plot(to_plot_daily.index, to_plot_daily[c], label=c)
            else:
                ax3.stackplot(to_plot_daily.index, to_plot_daily[cols_choose].T.values, labels=cols_choose)
            ax3.set_ylabel("Contribution quotidienne")
            ax3.set_title("Contributions PnL — quotidiennes")
        else:
            if style_mode == "Lignes":
                for c in cols_choose:
                    ax3.plot(to_plot_cum.index, to_plot_cum[c], label=c)
            else:
                ax3.stackplot(to_plot_cum.index, to_plot_cum[cols_choose].T.values, labels=cols_choose)
            ax3.set_ylabel("Contribution cumulative")
            ax3.set_title("Contributions PnL — cumulatives")
        ax3.set_xlabel("Date")
        ax3.legend(loc="upper left", ncols=2)
        auto_xticks(ax3, to_plot_daily.index)
        ax3.ticklabel_format(axis="y", style="plain")
        st.pyplot(fig3)
    else:
        st.info("Sélectionne au moins un facteur pour afficher ses contributions.")

    st.markdown("---")
    st.write("**Aperçu des contributions (derniers 30 jours)**")
    tailN = pnl_by_factor.tail(30).copy()
    tailN["TotalPnL"] = tailN.sum(axis=1)
    # tri recent → ancien
    tailN = tailN.reset_index().rename(columns={"index":"Date"}).sort_values("Date", ascending=False).set_index("Date")
    # réordonner avec TotalPnL en 1ère colonne
    cols_order = ["TotalPnL"] + [c for c in tailN.columns if c != "TotalPnL"]
    tailN = tailN[cols_order]
    try:
        st.dataframe(
            tailN.style.format("{:,.0f}").applymap(
                lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else ''
            ),
            use_container_width=True
        )
    except Exception:
        st.dataframe(tailN, use_container_width=True)

# ---------------------------------------------------------
# TAB 3 — Coût de hedge & PnL Hedged vs Baseline (LightGBM uniquement)
# ---------------------------------------------------------
with tab3:
    try:
        st.subheader("Coût de hedge et PnL net — α piloté par LightGBM (proba transition)")

        if 'pnl_by_factor' in globals() and isinstance(pnl_by_factor, pd.DataFrame) and not pnl_by_factor.empty:
            # Probabilités LGBM
            if 'proba_all' in globals() and isinstance(proba_all, pd.Series) and not proba_all.empty:
                proba_series = proba_all.reindex(pnl_by_factor.index).fillna(method='ffill')
                st.info("α piloté par **LightGBM** : probabilité de transition imminente.")
            else:
                st.error("Probabilités LightGBM indisponibles. Va dans Tab 4 pour entraîner le modèle.")
                proba_series = pd.Series(0.0, index=pnl_by_factor.index)

            # Coûts
            c1, c2, c3 = st.columns(3)
            with c1:
                cost_rate = st.number_input("Coût — Rates (par DV01)", 0.0, 5.0, 0.20, 0.01)
            with c2:
                cost_xccy = st.number_input("Coût — XCCY (par DV01)", 0.0, 5.0, 0.25, 0.01)
            with c3:
                cost_fx   = st.number_input("Coût — FX (par FX01)",   0.0, 5.0, 0.00, 0.01)

            # Mapping α = f(p)
            st.markdown("**Mapping α = f(p)** (seuillage piecewise)")
            d1, d2, d3 = st.columns(3)
            with d1:
                tau1 = st.slider("τ1 (→ α=0.3)", 0.0, 1.0, 0.50, 0.05)
            with d2:
                tau2 = st.slider("τ2 (→ α=0.6)", 0.0, 1.0, 0.70, 0.05)
            with d3:
                tau3 = st.slider("τ3 (→ α=1.0)", 0.0, 1.0, 0.85, 0.05)

            def alpha_from_p(p: float) -> float:
                if not np.isfinite(p):
                    return 0.0
                if p < tau1: return 0.0
                if p < tau2: return 0.3
                if p < tau3: return 0.6
                return 1.0

            # Buckets
            def _bucket(name: str) -> str:
                n = str(name).upper()
                if 'FX' in n or (name in FX_COLS): return 'FX'
                if 'XCCY' in n or 'BASIS' in n: return 'XCCY'
                return 'Rates'

            # Vecteurs
            risk_cols_loc = [c for c in pnl_by_factor.columns]
            bump_s_loc = mapping_df.reindex(risk_cols_loc)["Bump"].astype(float).where(lambda s: s.notna() & (s != 0.0))

            # Hedge simulation
            topN = st.slider("Top N constituants par jour à couvrir", 1, 20, 4, 1)
            contrib_after = pnl_by_factor.copy()
            cost_by_const = pd.Series(0.0, index=risk_cols_loc, dtype=float)

            for d in pnl_by_factor.index:
                pnl_row = pnl_by_factor.loc[d].reindex(risk_cols_loc)
                alpha_t = float(alpha_from_p(float(proba_series.get(d, 0.0))))
                if alpha_t <= 0: continue
                top_names = pnl_row.abs().sort_values(ascending=False).head(int(topN)).index.tolist()
                contrib_after.loc[d, top_names] = contrib_after.loc[d, top_names] * (1.0 - alpha_t)
                for cst in top_names:
                    pnl_c = float(pnl_row.get(cst, 0.0))
                    bump_c = float(bump_s_loc.get(cst, np.nan))
                    if not np.isfinite(bump_c) or abs(bump_c) < 1e-12: continue
                    units_alpha = (alpha_t * (pnl_c / bump_c))
                    b = _bucket(cst)
                    unit_cost = cost_fx if b == 'FX' else (cost_xccy if b == 'XCCY' else cost_rate)
                    cost_by_const.loc[cst] += abs(units_alpha) * unit_cost

            # Agrégation colonne
            base_totals   = pnl_by_factor.sum(axis=0).rename("BaseTotal")
            hedged_totals = contrib_after.sum(axis=0).rename("HedgedTotal_gross")
            cost_by_const = cost_by_const.rename("HedgeCost_alloc")
            hedged_net    = (hedged_totals - cost_by_const).rename("HedgedTotal_net")
            delta_total   = (hedged_net - base_totals).rename("Delta(HedgedNet-Base)")
            view_cols = pd.concat([base_totals, hedged_totals, cost_by_const, hedged_net, delta_total], axis=1).fillna(0.0)
            view_cols = view_cols.reindex(view_cols["Delta(HedgedNet-Base)"].abs().sort_values(ascending=False).index)

            st.dataframe(
                view_cols.style.format({
                    "BaseTotal": "{:,.0f}",
                    "HedgedTotal_gross": "{:,.0f}",
                    "HedgeCost_alloc": "{:,.0f}",
                    "HedgedTotal_net": "{:,.0f}",
                    "Delta(HedgedNet-Base)": "{:,.0f}",
                }).applymap(lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else ''),
                use_container_width=True, height=420
            )

            # KPIs globaux
            tot_base  = float(base_totals.sum())
            tot_hedge = float(hedged_net.sum())
            tot_cost  = float(cost_by_const.sum())
            k1, k2, k3 = st.columns(3)
            with k1: st.metric("Total Base (∑ colonnes)", f"{tot_base:,.0f}")
            with k2: st.metric("Total Hedged net (∑ colonnes)", f"{tot_hedge:,.0f}")
            with k3: st.metric("Coût total hedge (∑ colonnes)", f"{tot_cost:,.0f}")

            # Export
            st.download_button(
                "Télécharger (CSV) — Totaux par constituant (α = f(p))",
                data=view_cols.to_csv().encode("utf-8"),
                file_name="pnl_totaux_par_constituant_alpha_prob.csv",
                mime="text/csv"
            )
        else:
            st.info("Séries PnL indisponibles — impossible de calculer le hedge.")
    except Exception as _e_knn_cost_total:
        st.warning(f"Coût & PnL net (α=f(p)) non rendus: {_e_knn_cost_total}")

# ---------------------------------------------------------
# TAB 4 — Détection de transition (supervisé) : LightGBM
# ---------------------------------------------------------
with tab4:
    try:
        st.header("Détection de transition — Modèle LightGBM")

        c1, c2, c3, c4 = st.columns(4)
        with c1:
            horizon_next = st.slider("Horizon (jours)", 1, 10, 3)
        with c2:
            n_lags = st.slider("Nb lags ΔS", 1, 10, 3)
        with c3:
            test_size_pct = st.slider("Test size %", 10, 50, 20) / 100.0
        with c4:
            alert_thr = st.slider("Seuil alerte proba", 10, 90, 70) / 100.0

        from sklearn.metrics import roc_auc_score
        import lightgbm as lgb

        # Labels supervisés à partir de probas HMM pondérées (si dispo)
        if 'hmm_proba_stress_weighted' in globals() and isinstance(hmm_proba_stress_weighted, pd.Series) and not hmm_proba_stress_weighted.empty:
            signal = hmm_proba_stress_weighted
            # label: transition si variation > 5% dans les H jours suivants (simple proxy)
            trans_dates = signal.diff().abs() > 0.05
            all_idx = mkt_change.index
            y = pd.Series(0, index=all_idx, dtype=int)
            trans_idx = set(trans_dates[trans_dates].index)
            for t in all_idx:
                fut = [t + pd.Timedelta(days=h) for h in range(1, int(horizon_next)+1)]
                if any(f in trans_idx for f in fut):
                    y.loc[t] = 1
        else:
            # fallback: pas de labels (zéro)
            y = pd.Series(0, index=mkt_change.index, dtype=int)
            st.info("HMM pondéré non disponible — labels par défaut (rares). Va Tab 5 pour estimer HMM per-constituant.")

        # Features: lags de ΔS
        X_feat_list = []
        for lag in range(0, int(n_lags)):
            X_feat_list.append(mkt_change.shift(lag).add_suffix(f"_lag{lag}"))
        X_feat = pd.concat(X_feat_list, axis=1).dropna()
        y = y.reindex(X_feat.index).fillna(0).astype(int)

        # Split chronologique
        n_total = len(X_feat)
        n_test = max(1, int(np.floor(test_size_pct * n_total)))
        n_train = max(1, n_total - n_test)
        X_train, X_test = X_feat.iloc[:n_train], X_feat.iloc[n_train:]
        y_train, y_test = y.iloc[:n_train], y.iloc[n_train:]

        model = lgb.LGBMClassifier(n_estimators=400, learning_rate=0.05, num_leaves=31, subsample=0.9, colsample_bytree=0.9, random_state=42)
        model.fit(X_train, y_train)
        proba_all = pd.Series(model.predict_proba(X_feat)[:,1], index=X_feat.index, name="proba_transition")
        auc_train = roc_auc_score(y_train, model.predict_proba(X_train)[:,1]) if y_train.nunique()>1 else np.nan
        auc_test  = roc_auc_score(y_test,  model.predict_proba(X_test)[:,1])  if y_test.nunique()>1  else np.nan

        k1, k2 = st.columns(2)
        with k1: st.metric("AUC train", f"{auc_train:.3f}" if np.isfinite(auc_train) else "n/a")
        with k2: st.metric("AUC test",  f"{auc_test:.3f}"  if np.isfinite(auc_test)  else "n/a")
        st.line_chart(proba_all)
        st.caption("Cette probabilité alimente α dans Tab 3 et Tab 6.")

        # --- Comparatif HMM (per-constituant) vs LightGBM ---
        st.subheader("Comparatif — Proba HMM (pondérée) vs Proba LightGBM")
        if 'hmm_proba_stress_weighted' in globals() and isinstance(hmm_proba_stress_weighted, pd.Series) and not hmm_proba_stress_weighted.empty:
            cmp = pd.concat([
                proba_all.rename("LightGBM_proba"),
                hmm_proba_stress_weighted.rename("HMM_weighted_proba")
            ], axis=1).dropna()
            if not cmp.empty:
                st.line_chart(cmp)
                corr0 = float(cmp["LightGBM_proba"].corr(cmp["HMM_weighted_proba"]))
                c1c, c2c = st.columns(2)
                with c1c:
                    st.metric("Corrélation (t,t)", f"{corr0:.2f}")
                with c2c:
                    lead = st.slider("Décalage HMM vs LGBM (jours; + = HMM avance)", -5, 5, 0, 1, key="cmp_lead")
                    if lead != 0:
                        hmm_shift = hmm_proba_stress_weighted.shift(int(lead))
                        cmp2 = pd.concat([proba_all.rename("LightGBM_proba"), hmm_shift.rename("HMM_weighted_proba")], axis=1).dropna()
                        corrL = float(cmp2["LightGBM_proba"].corr(cmp2["HMM_weighted_proba"])) if len(cmp2)>2 else np.nan
                        st.metric("Corrélation (avec décalage)", f"{corrL:.2f}" if np.isfinite(corrL) else "n/a")

                st.markdown("**Scatter LightGBM vs HMM (contemporain)**")
                fig_sc, ax_sc = plt.subplots(figsize=(6,5), dpi=110)
                ax_sc.scatter(cmp["LightGBM_proba"], cmp["HMM_weighted_proba"], s=12, alpha=0.6)
                ax_sc.set_xlabel("LightGBM proba"); ax_sc.set_ylabel("HMM weighted proba")
                ax_sc.set_xlim(0,1); ax_sc.set_ylim(0,1)
                st.pyplot(fig_sc)
            else:
                st.info("Pas de recouvrement temporel suffisant entre HMM (Tab 5) et LightGBM.")
        else:
            st.info("HMM pondéré (Tab 5) non disponible : va d'abord estimer les HMM par constituant.")

    except Exception as _e_tab4:
        st.warning(f"Tab 4 (Détection de transition) non rendue: {_e_tab4}")

# ---------------------------------------------------------
# TAB 5 — HMM par constituant (moyenne pondérée)
# ---------------------------------------------------------
with tab5:
    try:
        st.header("HMM par constituant — Probabilité agrégée de stress (moyenne pondérée)")

        if isinstance(pnl_by_factor, pd.DataFrame) and not pnl_by_factor.empty:
            from hmmlearn.hmm import GaussianHMM
            cols = st.multiselect("Constituants à modéliser (HMM 1D chacun)",
                                  pnl_by_factor.columns.tolist(),
                                  default=list(pnl_by_factor.columns[:min(10, len(pnl_by_factor.columns))]))
            hmm_states_pc = st.slider("Nb régimes (par constituant)", 2, 4, 2, 1)

            proba_stress_f = {}
            for c in cols:
                s = pnl_by_factor[c].dropna()
                if len(s) < 50:  # garde-fou
                    continue
                Xc = s.values.reshape(-1,1)
                hmmc = GaussianHMM(n_components=int(hmm_states_pc), covariance_type='full', n_iter=200, random_state=42)
                hmmc.fit(Xc)
                means_c = hmmc.means_.reshape(-1)
                stress_c = int(np.argmin(means_c))
                prob_c = pd.Series(hmmc.predict_proba(Xc)[:, stress_c], index=s.index, name=f"stress_{c}")
                proba_stress_f[c] = prob_c

            if len(proba_stress_f):
                dfp = pd.DataFrame(proba_stress_f).reindex(pnl_by_factor.index).fillna(method='ffill')
                w = pnl_by_factor[cols].abs().mean()
                w = w / w.sum() if w.sum() > 0 else pd.Series(1/len(w), index=w.index)
                hmm_proba_stress_weighted = (dfp * w).sum(axis=1).rename("hmm_proba_stress_weighted")
                st.line_chart(hmm_proba_stress_weighted)
                st.caption("Série exposée pour Tab 4 (modèle LightGBM).")
            else:
                st.info("Pas assez de données pour estimer les HMM par constituant (ou séries trop courtes).")
        else:
            st.info("Contributions PnL indisponibles.")
    except Exception as _e_tab5:
        st.warning(f"Tab 5 (HMM par constituant) non rendue: {_e_tab5}")

# ---------------------------------------------------------
# TAB 6 — Forecast & Hedge Optimizer (LightGBM → α → plan de hedge)
# ---------------------------------------------------------
with tab6:
    try:
        st.header("Forecast & Hedge Optimizer — proba LightGBM → α → plan de hedge")

        if 'pnl_by_factor' not in globals() or not isinstance(pnl_by_factor, pd.DataFrame) or pnl_by_factor.empty:
            st.info("Séries PnL par constituant indisponibles.")
        elif 'proba_all' not in globals() or not isinstance(proba_all, pd.Series) or proba_all.empty:
            st.error("Probabilités LightGBM indisponibles. Va dans Tab 4 pour entraîner le modèle.")
        else:
            # Inputs
            c0, c1, c2, c3 = st.columns(4)
            with c0:
                topN = st.slider("Top N constituants/jour", 1, 20, 4, 1, key="fxhedge_topN")
            with c1:
                tau1 = st.slider("τ1 (→ α=0.3)", 0.0, 1.0, 0.50, 0.05, key="fxhedge_tau1")
            with c2:
                tau2 = st.slider("τ2 (→ α=0.6)", 0.0, 1.0, 0.70, 0.05, key="fxhedge_tau2")
            with c3:
                tau3 = st.slider("τ3 (→ α=1.0)", 0.0, 1.0, 0.85, 0.05, key="fxhedge_tau3")

            d0, d1, d2, d3 = st.columns(4)
            with d0:
                apply_day = st.selectbox("Appliquer le hedge", ["Jour T", "Jour T+1"], index=0, key="fxhedge_apply")
            with d1:
                cost_rate = st.number_input("Coût — Rates (par DV01)", 0.0, 5.0, 0.20, 0.01, key="fxhedge_cost_rate")
            with d2:
                cost_xccy = st.number_input("Coût — XCCY (par DV01)", 0.0, 5.0, 0.25, 0.01, key="fxhedge_cost_xccy")
            with d3:
                cost_fx   = st.number_input("Coût — FX (par FX01)",   0.0, 5.0, 0.00, 0.01, key="fxhedge_cost_fx")

            def alpha_from_p(p: float) -> float:
                if not np.isfinite(p):
                    return 0.0
                if p < tau1: return 0.0
                if p < tau2: return 0.3
                if p < tau3: return 0.6
                return 1.0

            # Séries
            risk_cols_loc = list(pnl_by_factor.columns)
            bump_s = mapping_df.reindex(risk_cols_loc)["Bump"].astype(float).where(lambda s: s.notna() & (s != 0.0))
            proba_series = proba_all.reindex(pnl_by_factor.index).fillna(method='ffill')

            def _bucket(name: str) -> str:
                u = str(name).upper()
                if 'FX' in u or (name in FX_COLS): return 'FX'
                if 'XCCY' in u or 'BASIS' in u:    return 'XCCY'
                return 'Rates'

            contrib_after = pnl_by_factor.copy()
            cost_series = pd.Series(0.0, index=pnl_by_factor.index)
            plan_rows = []

            for d in pnl_by_factor.index:
                p = float(proba_series.get(d, 0.0))
                a = float(alpha_from_p(p))
                if a <= 0:
                    continue
                pnl_row = pnl_by_factor.loc[d].reindex(risk_cols_loc)
                top_names = pnl_row.abs().sort_values(ascending=False).head(int(topN)).index.tolist()

                target_day = d if apply_day == "Jour T" else (d + pd.Timedelta(days=1))
                if target_day in contrib_after.index:
                    contrib_after.loc[target_day, top_names] = contrib_after.loc[target_day, top_names] * (1.0 - a)

                for c in top_names:
                    pnl_c  = float(pnl_row.get(c, 0.0))
                    bump_c = float(bump_s.get(c, np.nan))
                    if not np.isfinite(bump_c) or abs(bump_c) < 1e-12:
                        hedge_units = np.nan; unit_cost = 0.0
                    else:
                        hedge_units = -(a * (pnl_c / bump_c))
                        bucket = _bucket(c)
                        unit_cost = cost_fx if bucket == 'FX' else (cost_xccy if bucket == 'XCCY' else cost_rate)

                    if target_day in cost_series.index and np.isfinite(hedge_units):
                        cost_series.loc[target_day] += abs(hedge_units) * float(unit_cost)

                    plan_rows.append({
                        "Date": target_day,
                        "p_forecast": p,
                        "alpha": a,
                        "Constituant": c,
                        "PnL_contrib": pnl_c,
                        "Bump": bump_c,
                        "HedgeUnits": hedge_units,
                        "Bucket": _bucket(c),
                        "UnitCost": unit_cost,
                        "CostAlloc": (abs(hedge_units)*float(unit_cost)) if np.isfinite(hedge_units) else 0.0,
                    })

            plan_df = pd.DataFrame(plan_rows)

            # PnL baseline vs hedgé
            pnl_base  = pnl_by_factor.sum(axis=1).rename("PnL_baseline")
            pnl_after = contrib_after.sum(axis=1).rename("PnL_gross_after") - cost_series.rename("HedgeCost").reindex(pnl_by_factor.index).fillna(0.0)
            cum_base  = pnl_base.cumsum().rename("Cum_Base")
            cum_after = pnl_after.cumsum().rename("Cum_Hedged")

            figF, axF = plt.subplots(figsize=(12,5), dpi=120)
            axF.plot(cum_base.index,  cum_base.values,  label="Cumul Base")
            axF.plot(cum_after.index, cum_after.values, label="Cumul Hedgé")
            format_yaxis_plain(axF); auto_xticks(axF, cum_after.index)
            axF.set_title("Cumulative PnL — Base vs Hedgé (Forecast-driven)")
            axF.legend(loc='upper left')
            st.pyplot(figF)

            k1, k2, k3 = st.columns(3)
            with k1: st.metric("Δ Cumul (Hedgé-Base)", f"{float(cum_after.iloc[-1]-cum_base.iloc[-1]):,.0f}")
            with k2: st.metric("Coût total hedge", f"{float(cost_series.sum()):,.0f}")
            with k3: st.metric("% jours couverts", f"{100.0*float((proba_series.apply(alpha_from_p)>0).mean()):.1f}%")

            st.subheader("Plan de hedge (détaillé)")
            if plan_df.empty:
                st.info("Aucun hedge déclenché (probas sous seuils).")
            else:
                st.dataframe(
                    plan_df.sort_values(["Date","Constituant"])
                           .style.format({
                               "p_forecast":"{:.2f}", "alpha":"{:.2f}",
                               "PnL_contrib":"{:,.0f}", "Bump":"{:,.6f}",
                               "HedgeUnits":"{:,.0f}", "UnitCost":"{:,.3f}",
                               "CostAlloc":"{:,.0f}"
                           }).applymap(lambda v: 'color:red;' if isinstance(v,(int,float)) and v<0 else '',
                                       subset=['PnL_contrib','HedgeUnits','CostAlloc']),
                    use_container_width=True, height=420
                )
                st.download_button(
                    "Télécharger (CSV) — Plan de hedge",
                    data=plan_df.to_csv(index=False).encode('utf-8'),
                    file_name="forecast_hedge_plan.csv",
                    mime="text/csv"
                )

            st.subheader("Séries PnL — Base vs Hedgé")
            out_series = pd.concat([pnl_base, pnl_after, cum_base, cum_after, cost_series.rename("HedgeCost")], axis=1)
            st.download_button(
                "Télécharger (CSV) — Séries",
                data=out_series.to_csv().encode('utf-8'),
                file_name="forecast_hedge_series.csv",
                mime="text/csv"
            )
    except Exception as _e_tab6:
        st.warning(f"Tab 6 (Forecast & Hedge Optimizer) non rendue: {_e_tab6}")
